services:
  web:
    image: node:22.21.1-alpine
    #network_mode: bridge
    working_dir: /app
    command: sh -lc "npm ci && npm run dev"
    env_file: ./frontend/.env
    environment:
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
      - NEXT_TELEMETRY_DISABLED=1
    ports: ["3000:3000"]
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on: [api]

  api:
    image: node:22.21.1-alpine
    #network_mode: bridge
    working_dir: /app
    command: sh -lc "npm ci && npm run dev"
    env_file: ./backend/.env
    environment: [ NODE_ENV=development ]
    ports: ["4000:4000"]
    volumes:
      - ./backend:/app
      - /app/node_modules
    depends_on: [mongo, redis, llm]

  mongo:
    image: mongo:7.0.14
    volumes: [ "mongo-data:/data/db" ]

  redis:
    image: redis:7.2.4-alpine

  llm:
    image: ghcr.io/ggml-org/llama.cpp:full
    container_name: vn_llm
    volumes:
      - ./models:/models:ro
    ports:
      - "8082:8080"
    command: >
      --server
      -m /models/Arcee-VyLinh.Q4_K_M.gguf
      -c 2048
      --host 0.0.0.0
      --port 8080
      -t 2
    restart: unless-stopped

volumes:
  mongo-data:
